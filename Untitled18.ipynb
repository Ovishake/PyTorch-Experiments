{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                               transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomVerticalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifardata/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 169730048/170498071 [00:27<00:00, 8519126.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "170500096it [00:40, 8519126.00it/s]                               "
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.CIFAR10(root='./cifardata', train=True, download=True, transform=transform)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./cifardata', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "#Random Subset Sampler\n",
    "\n",
    "n_training_samples = 20000\n",
    "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
    "\n",
    "n_val_samples = 5000\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples + n_val_samples, dtype=np.int64))\n",
    "\n",
    "n_test_samples = 5000\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(n_test_samples)\n",
    "#npimg = np.transpose(npimg,(2,0,1))\n",
    "#cifar 10 is 32x32 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BengioCnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BengioCnn,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
    "        #18 filters and 3x3 kernel gives 32-3+1= 30 with padding gives 32x32x18\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(18 * 16 * 16, 64)\n",
    "        #inputs, outputs\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #32x32x3 --> 32x32x18 zero padding enabled with integer value\n",
    "        x = self.pool(x)\n",
    "        #32x32x18 --> 16x16x18\n",
    "        x = x.view(-1, 18 * 16 *16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_loader(batch_size):\n",
    "    #load the train data from train_set\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,sampler=train_sampler, num_workers=2)\n",
    "    return(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16, sampler=test_sampler, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=16, sampler=val_sampler, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x11f34c6a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x11f34ce48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def createLossAndOptimizer(net, learning_rate=0.001):\n",
    "    loss = torch.nn.CrossEntropyLoss\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "    train_loader = get_train_loader(batch_size)\n",
    "    n_batches = len(train_loader)\n",
    "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
    "    training_start_time = time.time()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = torch.nn.CrossEntropyLoss()\n",
    "            loss_size = loss(outputs, labels)\n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss_size.data\n",
    "            total_train_loss += loss_size.data\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            if (i + 1) % (print_every + 1) == 0:\n",
    "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "                print(\"Accuracy\", correct/total)\n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "                start_time = time.time()\n",
    "        total_val_loss = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            #Forward pass\n",
    "            val_outputs = net(inputs)\n",
    "            val_loss_size = loss(val_outputs, labels)\n",
    "            total_val_loss += val_loss_size.data\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            \n",
    "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
    "        print(\"Validation Loss\", correct/total)\n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b04a5260854b49974391a40d6424b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 10% \t train_loss: 2.13 took: 0.85s\n",
      "Accuracy 0.23561507936507936\n",
      "Epoch 1, 20% \t train_loss: 1.88 took: 0.75s\n",
      "Accuracy 0.28521825396825395\n",
      "Epoch 1, 30% \t train_loss: 1.74 took: 0.75s\n",
      "Accuracy 0.31994047619047616\n",
      "Epoch 1, 40% \t train_loss: 1.67 took: 0.75s\n",
      "Accuracy 0.3443700396825397\n",
      "Epoch 1, 50% \t train_loss: 1.57 took: 0.76s\n",
      "Accuracy 0.3649801587301587\n",
      "Epoch 1, 60% \t train_loss: 1.52 took: 0.77s\n",
      "Accuracy 0.3826058201058201\n",
      "Epoch 1, 70% \t train_loss: 1.47 took: 0.76s\n",
      "Accuracy 0.3955498866213152\n",
      "Epoch 1, 80% \t train_loss: 1.44 took: 0.74s\n",
      "Accuracy 0.40811011904761907\n",
      "Epoch 1, 90% \t train_loss: 1.46 took: 0.79s\n",
      "Accuracy 0.4177689594356261\n",
      "Validation loss = 1.32\n",
      "Validation Loss 0.44672\n",
      "Epoch 2, 10% \t train_loss: 1.29 took: 1.00s\n",
      "Accuracy 0.45454545454545453\n",
      "Epoch 2, 20% \t train_loss: 1.36 took: 1.64s\n",
      "Accuracy 0.4588040782584734\n",
      "Epoch 2, 30% \t train_loss: 1.29 took: 1.86s\n",
      "Accuracy 0.4652473589281113\n",
      "Epoch 2, 40% \t train_loss: 1.34 took: 1.49s\n",
      "Accuracy 0.46896927171546093\n",
      "Epoch 2, 50% \t train_loss: 1.28 took: 1.32s\n",
      "Accuracy 0.47397377423033066\n",
      "Epoch 2, 60% \t train_loss: 1.28 took: 1.32s\n",
      "Accuracy 0.478569117964201\n",
      "Epoch 2, 70% \t train_loss: 1.29 took: 1.30s\n",
      "Accuracy 0.4823327878911843\n",
      "Epoch 2, 80% \t train_loss: 1.31 took: 1.32s\n",
      "Accuracy 0.4858976852752383\n",
      "Epoch 2, 90% \t train_loss: 1.29 took: 1.41s\n",
      "Accuracy 0.4884340812163916\n",
      "Validation loss = 1.27\n",
      "Validation Loss 0.49628\n",
      "Epoch 3, 10% \t train_loss: 1.18 took: 1.39s\n",
      "Accuracy 0.4994424792371578\n",
      "Epoch 3, 20% \t train_loss: 1.21 took: 1.37s\n",
      "Accuracy 0.5028871779686112\n",
      "Epoch 3, 30% \t train_loss: 1.22 took: 1.34s\n",
      "Accuracy 0.5055844990008564\n",
      "Epoch 3, 40% \t train_loss: 1.16 took: 1.33s\n",
      "Accuracy 0.5087489666574814\n",
      "Epoch 3, 50% \t train_loss: 1.20 took: 1.43s\n",
      "Accuracy 0.5112849533954728\n",
      "Epoch 3, 60% \t train_loss: 1.19 took: 1.36s\n",
      "Accuracy 0.5135918577686164\n",
      "Epoch 3, 70% \t train_loss: 1.21 took: 1.36s\n",
      "Accuracy 0.5155665086099326\n",
      "Epoch 3, 80% \t train_loss: 1.15 took: 1.35s\n",
      "Accuracy 0.5183432131623518\n",
      "Epoch 3, 90% \t train_loss: 1.17 took: 1.46s\n",
      "Accuracy 0.5202365578774361\n",
      "Validation loss = 1.21\n",
      "Validation Loss 0.5248666666666667\n",
      "Epoch 4, 10% \t train_loss: 1.09 took: 1.44s\n",
      "Accuracy 0.5276046535784772\n",
      "Epoch 4, 20% \t train_loss: 1.08 took: 1.36s\n",
      "Accuracy 0.5300764247393461\n",
      "Epoch 4, 30% \t train_loss: 1.07 took: 1.32s\n",
      "Accuracy 0.5326226433718291\n",
      "Epoch 4, 40% \t train_loss: 1.07 took: 1.46s\n",
      "Accuracy 0.5348406048348262\n",
      "Epoch 4, 50% \t train_loss: 1.07 took: 1.35s\n",
      "Accuracy 0.5368594264221909\n",
      "Epoch 4, 60% \t train_loss: 1.11 took: 1.32s\n",
      "Accuracy 0.5389914577018462\n",
      "Epoch 4, 70% \t train_loss: 1.13 took: 1.44s\n",
      "Accuracy 0.5403537121824221\n",
      "Epoch 4, 80% \t train_loss: 1.10 took: 1.48s\n",
      "Accuracy 0.5420617153893424\n",
      "Epoch 4, 90% \t train_loss: 1.14 took: 1.52s\n",
      "Accuracy 0.5433522288070085\n",
      "Validation loss = 1.19\n",
      "Validation Loss 0.54669\n",
      "Epoch 5, 10% \t train_loss: 1.00 took: 1.43s\n",
      "Accuracy 0.5486296267252195\n",
      "Epoch 5, 20% \t train_loss: 1.04 took: 1.32s\n",
      "Accuracy 0.5505036911719471\n",
      "Epoch 5, 30% \t train_loss: 0.97 took: 1.32s\n",
      "Accuracy 0.5525611044055522\n",
      "Epoch 5, 40% \t train_loss: 1.08 took: 1.32s\n",
      "Accuracy 0.5539865265028131\n",
      "Epoch 5, 50% \t train_loss: 1.02 took: 1.32s\n",
      "Accuracy 0.5556595203488373\n",
      "Epoch 5, 60% \t train_loss: 0.97 took: 1.42s\n",
      "Accuracy 0.5574864401941193\n",
      "Epoch 5, 70% \t train_loss: 1.04 took: 1.41s\n",
      "Accuracy 0.5591962282669658\n",
      "Epoch 5, 80% \t train_loss: 1.02 took: 1.33s\n",
      "Accuracy 0.5607605400936897\n",
      "Epoch 5, 90% \t train_loss: 1.04 took: 1.32s\n",
      "Accuracy 0.5620852518959913\n",
      "Validation loss = 1.20\n",
      "Validation Loss 0.564208\n",
      "Training finished, took 68.78s\n"
     ]
    }
   ],
   "source": [
    "CNN = BengioCnn()\n",
    "trainNet(CNN, batch_size=32, n_epochs=5, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = os.getcwd()+'/'\n",
    "torch.save(CNN.state_dict(), \"net1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"net1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('conv1.weight', tensor([[[[-4.1645e-03,  1.0685e-01,  2.8640e-02],\n",
      "          [-3.2654e-02, -3.8756e-02,  1.4767e-01],\n",
      "          [ 9.5754e-02, -5.5373e-02, -4.7471e-02]],\n",
      "\n",
      "         [[ 1.5054e-03, -1.5772e-01, -1.0079e-01],\n",
      "          [-2.6362e-02,  5.0000e-02,  2.4332e-02],\n",
      "          [ 7.5570e-02, -3.6457e-02, -3.7877e-02]],\n",
      "\n",
      "         [[ 1.1107e-01,  1.9697e-01,  4.4523e-02],\n",
      "          [-8.1047e-02,  1.8663e-01, -1.6585e-02],\n",
      "          [ 7.9883e-03,  1.3264e-02,  1.3581e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1216e-01,  1.0258e-01,  4.7507e-01],\n",
      "          [ 1.6755e-02, -2.7106e-01,  8.6874e-02],\n",
      "          [ 1.1251e-01, -7.5832e-02, -1.6047e-01]],\n",
      "\n",
      "         [[ 3.1663e-03,  2.8124e-01,  3.6975e-01],\n",
      "          [-3.0467e-01, -1.9228e-01, -1.2775e-01],\n",
      "          [-1.7032e-02, -2.1580e-01, -2.0775e-01]],\n",
      "\n",
      "         [[ 1.5314e-02, -8.6361e-03,  1.5817e-01],\n",
      "          [ 1.4680e-01, -1.4304e-01,  2.9602e-02],\n",
      "          [ 4.8207e-02,  4.9198e-02, -7.5305e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8692e-01,  1.1318e-01,  1.7572e-01],\n",
      "          [-5.9608e-02, -1.0307e-01, -5.9386e-02],\n",
      "          [ 2.3887e-01, -5.1557e-02, -1.8943e-01]],\n",
      "\n",
      "         [[ 1.4657e-01,  1.8281e-01,  3.3373e-01],\n",
      "          [-2.1524e-02,  4.2995e-02, -1.6430e-01],\n",
      "          [ 1.4143e-01, -2.0527e-01, -5.8777e-02]],\n",
      "\n",
      "         [[ 1.0997e-01,  2.4773e-01,  2.1954e-03],\n",
      "          [-8.5926e-02,  1.3913e-01, -2.0963e-01],\n",
      "          [-1.1264e-01, -2.5194e-01, -1.7813e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4077e-01, -1.7931e-01, -1.0349e-01],\n",
      "          [ 1.9448e-02,  1.3903e-01, -1.9813e-01],\n",
      "          [ 3.1487e-01,  2.5791e-01,  3.6658e-02]],\n",
      "\n",
      "         [[-2.2450e-01, -1.0828e-01,  1.8208e-01],\n",
      "          [ 2.3639e-01, -6.6126e-03,  1.6460e-01],\n",
      "          [ 1.7226e-01,  1.6524e-01, -2.5571e-01]],\n",
      "\n",
      "         [[-2.1593e-01, -9.9231e-03,  2.1867e-01],\n",
      "          [-1.4441e-01, -1.2204e-01, -1.1925e-01],\n",
      "          [ 2.3672e-01, -5.4559e-02, -1.0097e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1276e-01,  6.9728e-02, -1.3005e-01],\n",
      "          [ 5.9844e-03,  1.5881e-01,  6.6002e-02],\n",
      "          [-1.1820e-01,  7.0082e-02,  1.2452e-01]],\n",
      "\n",
      "         [[-1.2163e-01, -1.6235e-01, -7.8588e-02],\n",
      "          [-1.2015e-01,  1.1384e-01, -1.2679e-01],\n",
      "          [ 1.8913e-01, -1.1589e-01,  1.0453e-01]],\n",
      "\n",
      "         [[-2.1114e-03, -1.4311e-01, -7.5040e-02],\n",
      "          [ 1.1698e-01, -2.0526e-02,  1.8680e-01],\n",
      "          [-7.8923e-02, -1.4636e-01,  1.4090e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.0936e-02, -1.5073e-01, -6.3878e-02],\n",
      "          [-1.2021e-01,  1.2375e-01, -1.7762e-01],\n",
      "          [ 8.3023e-02,  9.4100e-02, -1.5625e-01]],\n",
      "\n",
      "         [[ 9.1222e-02, -1.3653e-01,  5.6184e-02],\n",
      "          [-1.8253e-02, -1.0399e-01, -1.8827e-01],\n",
      "          [-8.0334e-03,  1.5940e-01, -1.5793e-01]],\n",
      "\n",
      "         [[ 2.6054e-01,  1.9101e-01, -8.7432e-02],\n",
      "          [ 2.6212e-01,  2.3851e-01, -1.2530e-01],\n",
      "          [ 2.4180e-01,  1.2276e-01,  1.5436e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1924e-01,  1.7827e-01,  4.8782e-03],\n",
      "          [-1.3454e-01,  1.4123e-01,  5.6536e-02],\n",
      "          [ 1.7558e-02,  1.2664e-01, -5.1866e-02]],\n",
      "\n",
      "         [[-1.2554e-01, -8.5930e-03,  1.8936e-01],\n",
      "          [ 4.4866e-02,  1.3041e-01,  1.4997e-02],\n",
      "          [-2.5891e-01, -7.8925e-02,  2.3455e-01]],\n",
      "\n",
      "         [[-4.1583e-02,  1.5188e-01,  6.6617e-02],\n",
      "          [-1.1406e-01, -1.5312e-01,  1.7808e-01],\n",
      "          [-1.3278e-01, -1.6156e-01,  1.3603e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8249e-01, -1.6666e-01,  1.9955e-01],\n",
      "          [ 1.7986e-01,  2.5595e-01, -2.7972e-01],\n",
      "          [-8.2450e-02, -2.3389e-01, -1.7987e-01]],\n",
      "\n",
      "         [[-1.7346e-01,  7.8005e-02,  1.6623e-01],\n",
      "          [ 2.5744e-01,  1.7327e-01, -9.1962e-02],\n",
      "          [-1.1578e-01,  9.5420e-02,  1.1475e-01]],\n",
      "\n",
      "         [[-1.2617e-01, -1.1427e-01,  5.4820e-02],\n",
      "          [ 2.4370e-01,  1.4168e-01, -3.0894e-02],\n",
      "          [-4.2559e-02, -2.0237e-01, -6.0889e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.2411e-01, -3.3892e-01, -2.3920e-03],\n",
      "          [-2.5087e-01,  1.3337e-01,  2.5935e-01],\n",
      "          [ 1.5398e-01,  1.0778e-01,  2.3550e-01]],\n",
      "\n",
      "         [[-2.0904e-01, -1.7651e-01, -2.2150e-01],\n",
      "          [ 9.1833e-02, -1.9203e-01,  2.3483e-01],\n",
      "          [-7.7913e-02, -1.5839e-02,  1.9924e-01]],\n",
      "\n",
      "         [[-4.7182e-02, -6.7868e-02, -1.2942e-01],\n",
      "          [ 9.2815e-02,  1.5057e-02,  2.1832e-01],\n",
      "          [ 7.5514e-02,  8.7548e-02, -4.2879e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1724e-01,  1.1242e-01,  5.4538e-02],\n",
      "          [ 1.0438e-01,  4.5251e-02, -2.2477e-01],\n",
      "          [-2.2038e-01,  2.2532e-01,  5.6953e-02]],\n",
      "\n",
      "         [[ 9.7650e-02,  8.6873e-02,  1.3466e-01],\n",
      "          [ 7.5707e-02,  1.9888e-01, -1.8583e-02],\n",
      "          [-1.3449e-01,  1.1681e-01,  2.5702e-01]],\n",
      "\n",
      "         [[ 5.7107e-02, -1.7849e-01, -2.1404e-01],\n",
      "          [ 8.8797e-02, -8.4581e-04, -1.5304e-01],\n",
      "          [-1.8489e-01, -1.2097e-02, -1.3820e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6039e-01,  2.9506e-01,  2.7050e-01],\n",
      "          [-1.2607e-02,  3.1481e-02,  5.2824e-02],\n",
      "          [-4.9114e-02,  1.6790e-01,  1.9000e-01]],\n",
      "\n",
      "         [[-2.5658e-01, -2.1626e-01, -1.3132e-01],\n",
      "          [-1.2522e-01,  6.8766e-02, -1.0113e-01],\n",
      "          [-9.3421e-02, -2.6991e-01, -2.1636e-01]],\n",
      "\n",
      "         [[ 1.1114e-01, -8.3846e-02, -1.4187e-01],\n",
      "          [ 1.4323e-01, -1.1054e-01,  4.4275e-02],\n",
      "          [ 1.5232e-01,  9.6846e-02,  8.5461e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.2898e-01, -9.8652e-03, -1.6056e-01],\n",
      "          [ 5.8389e-02, -2.1570e-01, -1.9876e-01],\n",
      "          [ 2.6467e-01,  2.2822e-01, -4.9913e-02]],\n",
      "\n",
      "         [[-2.0029e-01, -1.6412e-04, -3.0825e-01],\n",
      "          [-3.8530e-02, -4.8075e-02, -2.7102e-02],\n",
      "          [ 2.5788e-01,  1.5135e-01,  1.3889e-01]],\n",
      "\n",
      "         [[-2.3800e-02, -4.1937e-02,  2.6572e-02],\n",
      "          [ 1.0747e-01,  1.0519e-01,  5.2355e-02],\n",
      "          [-4.3621e-02,  6.3076e-03,  2.1161e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8079e-02, -1.5789e-01,  2.7877e-01],\n",
      "          [ 2.7305e-01, -3.0419e-02,  2.5021e-01],\n",
      "          [-7.6167e-02, -2.8938e-01,  9.5416e-02]],\n",
      "\n",
      "         [[ 2.7100e-01, -2.1394e-01, -1.9955e-01],\n",
      "          [ 5.8685e-02, -2.7768e-01, -1.2975e-01],\n",
      "          [ 1.2972e-01, -2.7105e-01,  1.2089e-02]],\n",
      "\n",
      "         [[ 2.5988e-01, -1.9209e-01,  8.3314e-03],\n",
      "          [ 3.6678e-02, -2.2959e-01,  9.7908e-02],\n",
      "          [-8.5969e-02, -5.2802e-02, -1.0739e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0671e-02, -1.1289e-01, -1.2350e-01],\n",
      "          [-1.8367e-01, -5.4563e-02, -4.6582e-02],\n",
      "          [-1.8277e-01, -1.4002e-01, -2.8991e-02]],\n",
      "\n",
      "         [[ 1.4997e-01, -1.5789e-01, -1.0502e-01],\n",
      "          [ 5.0959e-02, -2.2208e-01, -8.2010e-02],\n",
      "          [-1.8377e-01, -1.0326e-01,  1.1012e-02]],\n",
      "\n",
      "         [[ 4.3810e-02,  4.3631e-02,  4.5930e-02],\n",
      "          [ 6.8987e-02, -5.7642e-02, -8.2833e-02],\n",
      "          [ 1.5104e-01,  2.5175e-02, -8.9309e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2747e-02, -7.4597e-03, -2.2859e-01],\n",
      "          [ 3.2977e-01, -1.6079e-01, -9.4589e-02],\n",
      "          [ 1.3370e-01,  5.4916e-02, -2.1287e-01]],\n",
      "\n",
      "         [[ 2.6701e-01,  7.6983e-02, -1.4256e-01],\n",
      "          [ 2.1023e-01, -2.0224e-01, -1.6130e-01],\n",
      "          [ 3.0120e-01, -2.6615e-02, -2.1427e-01]],\n",
      "\n",
      "         [[ 1.0451e-01,  4.6114e-03, -2.0893e-01],\n",
      "          [ 2.7375e-01, -1.3304e-01, -1.0233e-01],\n",
      "          [ 2.4755e-02,  1.9182e-01, -1.6927e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7809e-01,  3.2965e-02, -1.5280e-01],\n",
      "          [ 1.4232e-01, -3.3296e-02, -2.1838e-01],\n",
      "          [ 2.7345e-01, -1.4659e-01, -2.1255e-01]],\n",
      "\n",
      "         [[-2.2846e-02,  4.3021e-02, -1.7349e-01],\n",
      "          [ 2.7658e-01, -2.9056e-02, -1.7246e-01],\n",
      "          [ 7.4267e-02, -5.1893e-02,  4.1783e-02]],\n",
      "\n",
      "         [[ 1.5211e-01,  2.4857e-02, -2.4321e-01],\n",
      "          [ 7.2546e-02,  1.2597e-01, -2.1549e-01],\n",
      "          [ 2.2733e-01, -1.3387e-01, -3.7748e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5339e-02, -2.2790e-01, -1.7994e-01],\n",
      "          [-2.8094e-01, -5.0747e-02,  1.0787e-02],\n",
      "          [-1.8740e-01, -1.5228e-01, -2.0211e-01]],\n",
      "\n",
      "         [[ 1.4736e-01,  1.6115e-01,  1.5299e-01],\n",
      "          [-8.9472e-02, -1.3607e-01, -1.4340e-01],\n",
      "          [ 1.6918e-01,  1.2719e-01,  1.3267e-02]],\n",
      "\n",
      "         [[ 9.8782e-02,  1.6432e-01,  7.0247e-02],\n",
      "          [-1.1124e-01,  5.3269e-02,  4.8185e-02],\n",
      "          [ 1.9232e-01,  2.4829e-01,  1.6018e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5362e-01,  1.9423e-01,  1.0815e-01],\n",
      "          [-2.6708e-03, -1.7565e-01,  1.7652e-01],\n",
      "          [ 1.4715e-01,  2.3140e-02, -1.1167e-01]],\n",
      "\n",
      "         [[-1.2053e-01, -1.3916e-01,  9.6727e-04],\n",
      "          [-1.8442e-01,  9.6901e-03,  7.9104e-02],\n",
      "          [ 3.4712e-01, -1.8827e-01, -2.4641e-01]],\n",
      "\n",
      "         [[-1.4191e-01,  2.3734e-01,  2.0090e-01],\n",
      "          [-1.7711e-01, -1.3130e-01,  1.1081e-01],\n",
      "          [ 2.5916e-01, -4.9832e-02, -1.5025e-01]]]])), ('conv1.bias', tensor([ 0.0449, -0.1369, -0.2172, -0.1632, -0.0029, -0.1404,  0.0339,  0.0847,\n",
      "        -0.1468, -0.0174,  0.0102, -0.1638, -0.1887, -0.3711, -0.0300, -0.0644,\n",
      "         0.1703,  0.0636])), ('fc1.weight', tensor([[ 0.0009, -0.0056, -0.0057,  ..., -0.0544,  0.0052, -0.0034],\n",
      "        [-0.0117, -0.0128,  0.0047,  ..., -0.0005, -0.0233, -0.0134],\n",
      "        [ 0.0373,  0.0197,  0.0302,  ..., -0.1277, -0.1545, -0.1002],\n",
      "        ...,\n",
      "        [-0.0103,  0.0057, -0.0215,  ..., -0.0096, -0.0122, -0.0103],\n",
      "        [ 0.0029,  0.0298,  0.0189,  ...,  0.0919,  0.0740,  0.0322],\n",
      "        [-0.0077, -0.0061,  0.0076,  ..., -0.0092, -0.0132, -0.0006]])), ('fc1.bias', tensor([ 0.0449,  0.0025, -0.0732, -0.0114, -0.0106, -0.0896, -0.0144,  0.0566,\n",
      "         0.0061,  0.0070, -0.0055,  0.0080,  0.0031, -0.0003,  0.0084,  0.0373,\n",
      "         0.1239, -0.0011, -0.0020, -0.0097, -0.0058,  0.0639, -0.0155,  0.0056,\n",
      "        -0.0069,  0.0777, -0.0599, -0.0211,  0.0062, -0.0210, -0.0154,  0.0725,\n",
      "         0.0685, -0.0141, -0.0016, -0.0111,  0.0449,  0.0801, -0.0046,  0.0023,\n",
      "        -0.0013,  0.0053, -0.0032,  0.0476, -0.0202,  0.1612,  0.0024, -0.0200,\n",
      "         0.0034,  0.0029,  0.1403,  0.1089, -0.0199, -0.0041,  0.0592, -0.0019,\n",
      "        -0.0032, -0.0218, -0.0066,  0.0078, -0.0573, -0.0285,  0.0665,  0.0004])), ('fc2.weight', tensor([[ 2.6742e-02, -2.6435e-02,  3.4811e-04,  9.2584e-02,  4.1423e-02,\n",
      "         -6.9805e-02, -5.9529e-02,  1.0665e-02,  2.8461e-02,  4.8454e-02,\n",
      "          3.4314e-02,  4.4190e-02, -1.2217e-01, -1.5201e-02, -9.1944e-02,\n",
      "         -1.2799e-01, -1.3086e-02, -8.9291e-02,  1.2269e-01, -2.1634e-02,\n",
      "          5.8074e-02,  5.4903e-02,  1.1287e-01,  2.4699e-02, -2.1199e-02,\n",
      "          8.1174e-02, -1.3363e-01, -1.3125e-01, -1.0123e-01, -6.7096e-02,\n",
      "          7.7660e-02, -8.8710e-02,  9.1308e-02,  9.0338e-02,  1.0572e-02,\n",
      "          3.3144e-02, -1.8487e-01, -9.9839e-02, -3.1396e-02, -3.1338e-02,\n",
      "         -6.4533e-02,  7.1773e-02,  5.3415e-02, -1.5527e-01,  1.2025e-01,\n",
      "         -1.4716e-01, -6.5047e-02,  2.6821e-02, -1.2695e-01, -6.6203e-02,\n",
      "          1.6720e-01,  1.3385e-01, -4.1117e-02,  8.0659e-02,  5.5298e-02,\n",
      "          4.8951e-02, -7.3404e-02, -9.2306e-02,  1.6808e-01, -1.0736e-01,\n",
      "         -4.5619e-02,  7.7914e-02, -1.5413e-01,  7.8674e-02],\n",
      "        [ 1.8381e-01,  1.1685e-01,  1.5767e-01, -9.1860e-02,  5.3197e-02,\n",
      "          4.9541e-02,  1.2340e-02, -6.8625e-02,  9.8971e-02, -3.6109e-02,\n",
      "          1.7042e-03, -7.2393e-02, -1.0694e-01,  7.8795e-02, -6.1543e-02,\n",
      "         -1.0459e-01, -3.3493e-01, -1.2029e-01, -1.0132e-01, -8.1493e-02,\n",
      "         -1.1193e-01,  8.3169e-05,  8.1399e-02, -6.7869e-02,  3.1056e-02,\n",
      "         -1.7559e-01,  2.0336e-01, -1.2145e-01,  1.2694e-02, -5.5261e-02,\n",
      "         -4.8504e-02, -2.1665e-02, -1.2872e-01,  1.0715e-01, -4.0825e-02,\n",
      "         -8.7203e-02, -9.0748e-02,  9.1128e-03, -4.3497e-02,  5.1078e-02,\n",
      "         -5.9248e-02,  5.3981e-02,  1.2055e-01,  5.3076e-03,  1.3860e-01,\n",
      "         -2.0109e-01, -1.8883e-03,  1.0064e-01,  1.4122e-01, -1.0009e-01,\n",
      "         -1.5994e-01,  2.1306e-02, -1.0649e-01,  1.8368e-02, -4.8292e-02,\n",
      "         -6.4402e-02, -1.4323e-02,  1.1870e-01,  6.0382e-02, -1.0469e-01,\n",
      "         -2.2749e-01, -5.7404e-02, -3.0002e-01, -4.2816e-03],\n",
      "        [-4.0760e-02,  5.4417e-02, -1.1850e-01,  7.7356e-02, -8.3675e-04,\n",
      "         -1.5455e-01,  4.8907e-02,  8.3327e-02, -4.5531e-02,  4.8557e-02,\n",
      "          1.6173e-02, -1.0717e-01,  1.0988e-01,  5.9347e-03, -7.3773e-02,\n",
      "          1.1128e-01,  3.8768e-02,  6.0180e-02, -1.6724e-02, -5.0446e-02,\n",
      "          6.4161e-02, -3.0573e-02,  5.8250e-02, -4.6070e-02,  9.7260e-02,\n",
      "          1.1976e-01,  8.7354e-02, -2.2801e-02, -1.2116e-01, -1.0615e-01,\n",
      "          1.0066e-01,  1.5314e-01,  1.9612e-01, -7.8328e-02, -7.0566e-03,\n",
      "         -4.7173e-03,  8.7833e-02,  3.7577e-02,  1.5767e-02, -3.0045e-02,\n",
      "          1.9634e-02, -7.4545e-02,  2.5043e-02, -1.2985e-01,  1.4073e-01,\n",
      "         -1.5596e-02,  9.7850e-02,  4.1012e-02, -8.8802e-02, -4.7527e-02,\n",
      "          9.5092e-02,  3.3199e-02, -3.7790e-02, -4.7822e-02, -1.0699e-01,\n",
      "          5.0433e-02,  2.4034e-02, -5.8046e-02, -2.0137e-01,  8.0063e-02,\n",
      "         -1.2908e-01, -4.9941e-02,  1.1398e-01,  2.1371e-02],\n",
      "        [-1.6706e-01, -2.8731e-02,  4.7961e-02, -6.8258e-02,  4.2198e-03,\n",
      "         -1.3648e-01,  6.8387e-03, -1.3265e-01,  9.6308e-02, -8.4797e-02,\n",
      "          1.5870e-03,  9.1222e-03,  1.0656e-02, -3.4507e-02,  5.8389e-03,\n",
      "          1.2666e-01,  6.1698e-02, -5.2368e-02,  5.5532e-02, -3.9347e-02,\n",
      "          8.2612e-03, -4.2048e-02,  3.7236e-02, -8.0442e-02,  1.0819e-01,\n",
      "         -2.1408e-02, -1.0597e-01, -8.7679e-03, -8.1313e-02, -1.1025e-01,\n",
      "          6.2282e-02, -2.4447e-02, -7.3131e-02, -1.2063e-01,  9.6460e-02,\n",
      "          5.4907e-02, -2.6515e-02,  6.4225e-02, -6.1267e-02, -1.0050e-01,\n",
      "         -1.1395e-01, -1.7341e-02, -9.2358e-03,  1.3560e-01,  2.4539e-02,\n",
      "          1.9309e-01, -6.2497e-02,  1.1708e-01,  6.2948e-02, -4.3103e-02,\n",
      "         -4.9540e-02, -7.3678e-02,  1.5967e-02, -7.2327e-02,  7.8364e-02,\n",
      "          4.8074e-02, -6.2114e-02,  3.6130e-02,  1.4020e-02, -6.8904e-02,\n",
      "          8.7869e-03, -1.0265e-01,  2.5303e-02, -3.6537e-02],\n",
      "        [-6.0658e-02,  1.0888e-01, -1.2271e-01, -3.9477e-03, -1.1676e-01,\n",
      "          9.3780e-02,  1.0461e-01, -1.3507e-01, -5.3722e-03, -4.9405e-02,\n",
      "          1.0416e-01, -6.8016e-02, -1.7534e-02,  1.4778e-02,  5.7508e-02,\n",
      "         -4.4906e-02,  1.1049e-01, -1.1433e-01, -1.4428e-01,  2.7840e-02,\n",
      "          3.8530e-02, -5.3006e-02,  3.9810e-02, -7.7357e-02, -1.1420e-01,\n",
      "          1.2240e-01, -9.6942e-02, -1.1596e-01,  4.3218e-02, -8.0609e-02,\n",
      "         -1.2020e-01,  3.8695e-02, -1.2643e-01,  1.3471e-01, -2.1494e-02,\n",
      "          9.0557e-02, -1.1095e-01, -5.8782e-02,  9.4176e-02,  1.1493e-01,\n",
      "          3.7366e-02, -5.7785e-02,  1.0393e-01,  1.9493e-01, -9.3512e-02,\n",
      "         -3.5767e-02, -7.6447e-02, -5.8307e-02,  9.0484e-02, -2.5756e-02,\n",
      "          1.3802e-01,  1.8498e-01,  4.2294e-02, -9.0708e-02,  2.1069e-01,\n",
      "         -4.2806e-04,  2.3651e-02, -8.8925e-02, -1.1467e-01,  5.6667e-02,\n",
      "         -2.1948e-01,  7.7985e-02,  1.2879e-01,  1.8585e-02],\n",
      "        [ 6.7941e-02,  1.1543e-01,  4.5637e-02, -6.3926e-02, -6.3448e-02,\n",
      "         -1.1053e-01,  7.5184e-02, -1.1363e-01, -1.2500e-02,  7.3105e-03,\n",
      "          8.6824e-02,  7.8169e-02,  6.9322e-02, -1.2116e-01,  8.0292e-02,\n",
      "         -1.3972e-01,  1.8078e-01, -5.7621e-02, -4.9452e-02, -3.3593e-02,\n",
      "         -5.0143e-02, -1.3290e-01, -2.2514e-02,  9.8488e-02, -5.4527e-02,\n",
      "         -5.3857e-02, -1.5041e-01, -2.8889e-02,  8.9747e-02, -1.1218e-01,\n",
      "          7.3492e-02,  1.6566e-01, -1.3075e-01, -1.3185e-01,  1.1009e-01,\n",
      "          1.1879e-01,  1.8617e-01, -1.6621e-01,  4.4669e-02, -9.7033e-02,\n",
      "          6.6174e-02, -8.4606e-02,  6.2874e-02, -1.0401e-03, -1.1463e-01,\n",
      "          9.1328e-02, -8.6324e-03, -3.7521e-02,  9.8774e-02,  7.3134e-02,\n",
      "         -3.6754e-02, -1.1162e-01, -9.4457e-02,  8.9730e-02,  1.2016e-02,\n",
      "          6.4256e-03,  4.2096e-02, -5.3189e-03, -7.5994e-02, -1.1695e-01,\n",
      "          1.4176e-01, -1.4529e-02,  1.6176e-02, -1.1565e-01],\n",
      "        [-2.5103e-01, -6.5320e-02, -6.5120e-02, -6.6823e-02,  2.7890e-02,\n",
      "          1.1377e-01,  8.6997e-02, -2.6148e-01, -9.5447e-02, -1.7362e-02,\n",
      "         -7.3531e-02, -1.2096e-01, -9.0075e-02,  3.0830e-02,  1.1693e-01,\n",
      "          2.1689e-01, -4.9330e-02, -1.4005e-02,  2.2661e-01, -3.2830e-02,\n",
      "          5.8705e-03, -1.3652e-01, -9.8436e-02,  4.3544e-02,  1.1811e-01,\n",
      "          6.7919e-02,  9.2815e-02, -2.5376e-02,  1.1767e-01, -1.2179e-01,\n",
      "          1.0479e-01, -2.1599e-01,  1.5393e-01,  1.5280e-01, -1.3734e-02,\n",
      "          9.8561e-02,  3.7030e-02, -1.5976e-01,  4.7806e-02,  1.4661e-02,\n",
      "          7.4467e-02,  6.7808e-02,  1.5390e-02,  1.6164e-02, -2.6878e-02,\n",
      "         -1.3715e-01, -1.0519e-01,  9.6134e-02, -5.8094e-02,  2.8724e-02,\n",
      "         -1.9887e-01, -1.7368e-02,  8.1685e-02, -5.5900e-02, -4.0948e-02,\n",
      "         -6.6724e-02, -1.0090e-02,  1.1799e-02, -1.2375e-01,  2.2964e-02,\n",
      "          1.4684e-01,  1.7336e-02,  1.2308e-01,  2.9097e-02],\n",
      "        [ 1.3348e-02, -6.5652e-02,  3.8601e-02, -1.9945e-02,  8.5368e-02,\n",
      "         -6.1966e-02, -7.1495e-02,  9.1470e-02,  1.7867e-02,  5.9001e-02,\n",
      "          6.6673e-02,  4.5292e-02,  1.0241e-02,  2.5494e-02, -3.1472e-02,\n",
      "         -5.8656e-02, -2.0740e-01, -1.0806e-01, -7.2075e-02,  3.7854e-02,\n",
      "         -1.0194e-01, -2.4216e-01,  7.1688e-02,  1.1065e-01, -5.9925e-03,\n",
      "          1.9116e-01, -2.1361e-02,  5.9674e-02,  6.0304e-02, -1.0153e-01,\n",
      "         -8.6627e-02,  1.6721e-01, -1.4237e-01,  4.2770e-02, -5.4588e-02,\n",
      "          1.0452e-01, -2.4292e-01, -6.5357e-02,  4.0898e-02,  1.1732e-01,\n",
      "         -1.1348e-01, -4.3263e-02, -1.3841e-02, -2.5004e-01, -2.3386e-01,\n",
      "          9.3838e-02,  2.3651e-02,  1.1125e-01,  2.2470e-01,  7.0376e-02,\n",
      "          1.3561e-01, -1.8922e-01,  8.0327e-02, -2.7614e-02,  1.8079e-01,\n",
      "         -1.1694e-01,  7.3432e-02, -1.0739e-01, -3.5699e-02,  1.0250e-01,\n",
      "          6.0343e-02,  6.3656e-03,  1.1638e-02, -2.0814e-02],\n",
      "        [ 2.3459e-01, -8.4288e-02, -1.6297e-01, -1.1473e-01,  1.0924e-01,\n",
      "          4.5197e-02,  5.1904e-02,  1.5631e-01, -7.1479e-03,  3.7956e-02,\n",
      "          8.1195e-02,  7.1927e-02, -1.0495e-01,  1.0087e-01,  1.1571e-01,\n",
      "         -1.1396e-01,  3.8425e-02, -4.8848e-02,  2.0030e-01, -7.0518e-02,\n",
      "         -3.7174e-02,  2.9929e-02, -2.7755e-02, -9.8391e-02, -1.9833e-02,\n",
      "         -3.1096e-01,  1.5072e-01, -9.2791e-02, -7.2647e-02,  8.3043e-02,\n",
      "         -5.1852e-02, -1.8773e-01, -9.3041e-02, -1.2728e-01,  3.9161e-02,\n",
      "         -8.2838e-02, -7.4026e-02,  1.2370e-01, -9.0884e-02,  9.0347e-02,\n",
      "         -7.8500e-02,  5.5614e-02,  1.8156e-02, -1.4297e-01, -6.7441e-02,\n",
      "          8.8656e-02, -6.6236e-05, -4.0177e-02, -2.0679e-01,  5.7561e-03,\n",
      "         -3.9918e-02,  1.6716e-01,  4.7483e-02, -4.8900e-02, -1.7776e-01,\n",
      "         -1.1084e-01, -5.1030e-02,  5.6620e-02,  3.5458e-02, -2.7306e-02,\n",
      "         -2.5455e-02, -1.3731e-01, -1.3860e-01,  4.2634e-02],\n",
      "        [-1.2276e-01,  7.9627e-02,  2.0480e-01,  4.1232e-04,  8.0051e-02,\n",
      "          1.4436e-01,  5.1341e-02,  2.2235e-01, -3.4326e-02,  5.1764e-02,\n",
      "          1.1506e-02, -1.2238e-02,  6.9969e-02, -8.4594e-02,  5.8735e-02,\n",
      "         -1.2888e-01, -2.0770e-01, -7.4791e-02, -2.0916e-01, -3.8834e-02,\n",
      "          1.0281e-01, -6.4860e-02,  1.1274e-01, -1.3092e-01,  7.9894e-02,\n",
      "         -1.8152e-01, -8.4440e-03, -3.2422e-02,  3.6497e-02, -1.0370e-01,\n",
      "         -3.1990e-02,  4.4777e-02, -1.8425e-01, -1.4923e-01,  7.2704e-02,\n",
      "          5.1959e-02, -1.2811e-01, -4.9546e-03,  9.9227e-02,  1.0134e-01,\n",
      "         -1.2684e-02, -1.0151e-01,  4.2631e-02, -6.4343e-02,  1.0949e-01,\n",
      "         -1.5249e-01, -4.7331e-02, -6.4132e-02,  2.2329e-02,  3.7604e-02,\n",
      "         -2.1596e-01, -8.8468e-02,  1.0292e-01, -2.0000e-02, -5.2242e-02,\n",
      "         -1.8684e-04,  6.0424e-02,  3.0853e-02,  2.2311e-02,  6.6416e-02,\n",
      "         -1.3501e-02,  6.6629e-02, -3.4434e-02,  7.6865e-02]])), ('fc2.bias', tensor([ 0.0448, -0.1357, -0.0540,  0.0151, -0.0169, -0.1303, -0.0761, -0.1627,\n",
      "         0.1169, -0.0258]))])\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
